# -*- coding: utf-8 -*-
"""StudentPerfomanceAnalysis.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1htbOg5VqSH6fXXiGeMI2cvFlAh6fGCsq
"""

import pandas as pd
import seaborn as sns
from matplotlib import pyplot
import matplotlib.pyplot as plt
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn import tree
from sklearn import svm
from sklearn.metrics import confusion_matrix
from sklearn.metrics import accuracy_score
from sklearn.metrics import precision_score
from sklearn.metrics import recall_score
from sklearn.metrics import f1_score
from sklearn.metrics import classification_report
from sklearn.metrics import balanced_accuracy_score
from sklearn.metrics import cohen_kappa_score
from sklearn.metrics import roc_auc_score
from sklearn.linear_model import LogisticRegression

# dados da base de port
port_data = pd.read_csv("students/student-por.csv", delimiter=';')
port_data

port_data.hist()
pyplot.show()

port_data.shape

# tipos das colunas
port_data.dtypes

# verificando total de dados duplicados
port_data.duplicated().sum()

# verficando colunas com valores NaN
port_data.isna().any()

"""# **Pré-processamento dos dados**

Foi convertido os valores de variáveis categóricas para valores numéricos.

Acabei fazendo de forma mais manual para ter um controle melhor, como o dataset
para os exercícios é mais controlado eu optei por fazer desta forma.

Para a maioria das variáveis apenas converti o valor categórico para 0 ou 1.

Para outros casos foram criados mais valores.
"""

# convertendo variáveis categóricas para numéricas

# [GP = 0, MS = 1]
port_data['school'].replace(['GP','MS'], [0,1], inplace=True)

# [F = 0, M = 1]
port_data['sex'].replace(['F','M'], [0,1], inplace=True)

# [U = 0, R = 1]
port_data['address'].replace(['U','R'], [0,1], inplace=True)

# [LE3 = 0, GT3 = 1]
port_data['famsize'].replace(['LE3','GT3'], [0,1], inplace=True)

# [T = 0, A = 1]
port_data['Pstatus'].replace(['T','A'], [0,1], inplace=True)

# [teacher = 0, health = 1, services = 2, at_home = 3, other = 4]
port_data['Mjob'].replace(['teacher','health','services','at_home','other'], [0,1,2,3,4], inplace=True)
port_data['Fjob'].replace(['teacher','health','services','at_home','other'], [0,1,2,3,4], inplace=True)

# [mother = 0, father = 1, other = 2]
port_data['guardian'].replace(['mother','father','other'], [0,1,2], inplace=True)

# [no = 0, yes = 1]
port_data['schoolsup'].replace(['no','yes'], [0,1], inplace=True)

# [no = 0, yes = 1]
port_data['famsup'].replace(['no','yes'], [0,1], inplace=True)

# [no = 0, yes = 1]
port_data['paid'].replace(['no','yes'], [0,1], inplace=True)

# [no = 0, yes = 1]
port_data['activities'].replace(['no','yes'], [0,1], inplace=True)

# [no = 0, yes = 1]
port_data['nursery'].replace(['no','yes'], [0,1], inplace=True)

# [no = 0, yes = 1]
port_data['higher'].replace(['no','yes'], [0,1], inplace=True)

# [no = 0, yes = 1]
port_data['internet'].replace(['no','yes'], [0,1], inplace=True)

# [no = 0, yes = 1]
port_data['romantic'].replace(['no','yes'], [0,1], inplace=True)

port_data

# tirando algumas colunas que para mim não são necessárias
df = port_data
df = df.drop(['Mjob', 'Fjob', 'reason', 'romantic'], axis=1)
df

# Gerando um heatmap para enteder quais variáveis estão mais correlacionadas
sns.heatmap(df.corr(), xticklabels=True, yticklabels=True, annot=False, vmin=-1, vmax=1, cmap='coolwarm')
plt.show()

# y -> target (variavel dependete)
# x -> variaveis independentes
y = df[["G3"]]
x = df[["Medu", "Fedu", "studytime", "higher", "internet", "schoolsup", "famsup", "freetime", "goout", "Dalc", "Walc", "G1", "G2"]]

# Gerando um novo heatmap apenas com as variáveis selecionadas para o treinamento
sns.heatmap(x.corr(), xticklabels=True, yticklabels=True, annot=False, vmin=-1, vmax=1, cmap='coolwarm')
plt.show()

# fazendo split do dataset
x_train, x_test, y_train, y_test = train_test_split(x, y)

"""# **Diferentes modelos**

1.   Regressão linear
2.   Árvores de decisão
3.   SVM
4.   Regressão probabilistica


"""

# criando um modelo de regressão linear
reg = LinearRegression()
reg.fit(x_train, y_train)

reg.score(x_train, y_train)

# predicoes
y_pred = reg.predict(x_test)

# passando o vetor das predições para um dataframe
grade_predictions = pd.DataFrame(y_pred, columns=['Predição das notas'])


# inserindo uma nova coluna para conceito
grade_predictions.insert(1, "Conceito Final", True)

cols = grade_predictions.columns.tolist()

grade_predictions['Conceito Final'] = grade_predictions['Predição das notas'].where(grade_predictions['Predição das notas'] >= 12, other=False)
grade_predictions['Conceito Final'] = grade_predictions['Conceito Final'].where(grade_predictions['Conceito Final'] == False, other=True)
grade_predictions

#grade_predictions.to_csv('out.csv', index=False)

# criando um modelo de árvores de decisão
clf = tree.DecisionTreeClassifier()
clf = clf.fit(x_train, y_train)


y_pred = clf.predict(x_test)

# matriz de confusão
cm = confusion_matrix(y_test, y_pred)

# acurácia
acc = accuracy_score(y_test, y_pred)

# precisão
precision = precision_score(y_test, y_pred, average=None, zero_division=1)

# recall
recall = recall_score(y_test, y_pred, average=None, zero_division=1)

# acurácia balanceada
ba = balanced_accuracy_score(y_test, y_pred)

# kappa
kappa = cohen_kappa_score(y_test, y_pred)

print(clf.score(x_train, y_train))

print(classification_report(y_test, y_pred, zero_division=1))

grade_predictions = pd.DataFrame(y_pred, columns=['Predição das notas'])

# inserindo uma nova coluna para conceito
grade_predictions.insert(1, "Conceito Final", True)

cols = grade_predictions.columns.tolist()

grade_predictions['Conceito Final'] = grade_predictions['Predição das notas'].where(grade_predictions['Predição das notas'] >= 12, other=0)
grade_predictions['Conceito Final'] = grade_predictions['Conceito Final'].where(grade_predictions['Conceito Final'] == False, other=1)
grade_predictions

# criando um modelo de svm
clf = svm.SVC()
clf.fit(x_train, y_train.values.ravel())


y_pred = clf.predict(x_test)

# matriz de confusão
cm = confusion_matrix(y_test, y_pred)

# acurácia
acc = accuracy_score(y_test, y_pred)

# precisão
precision = precision_score(y_test, y_pred, average=None, zero_division=1)

# recall
recall = recall_score(y_test, y_pred, average=None, zero_division=1)

# f1 score
f1 = f1_score(y_test, y_pred, average=None)

# acurácia balanceada
ba = balanced_accuracy_score(y_test, y_pred)

# kappa
kappa = cohen_kappa_score(y_test, y_pred)

print(clf.score(x_train, y_train))

print(classification_report(y_test, y_pred, zero_division=1))

grade_predictions = pd.DataFrame(y_pred, columns=['Predição das notas'])

# inserindo uma nova coluna para conceito
grade_predictions.insert(1, "Conceito Final", True)

cols = grade_predictions.columns.tolist()

grade_predictions['Conceito Final'] = grade_predictions['Predição das notas'].where(grade_predictions['Predição das notas'] >= 12, other=0)
grade_predictions['Conceito Final'] = grade_predictions['Conceito Final'].where(grade_predictions['Conceito Final'] == False, other=1)
grade_predictions

# criando um modelo de regressão logistica
clf = LogisticRegression(solver='lbfgs', max_iter=5000)
clf.fit(x_train, y_train.values.ravel())

y_pred = clf.predict(x_test)

# matriz de confusão
cm = confusion_matrix(y_test, y_pred)

# acurácia
acc = accuracy_score(y_test, y_pred)

# precisão
precision = precision_score(y_test, y_pred, average=None, zero_division=1)

# recall
recall = recall_score(y_test, y_pred, average=None, zero_division=1)

# f1 score
f1 = f1_score(y_test, y_pred, average=None)

# acurácia balanceada
ba = balanced_accuracy_score(y_test, y_pred)

# kappa
kappa = cohen_kappa_score(y_test, y_pred)

print(clf.score(x_train, y_train))

print(classification_report(y_test, y_pred, zero_division=1))

grade_predictions = pd.DataFrame(y_pred, columns=['Predição das notas'])

# inserindo uma nova coluna para conceito
grade_predictions.insert(1, "Conceito Final", True)

cols = grade_predictions.columns.tolist()

grade_predictions['Conceito Final'] = grade_predictions['Predição das notas'].where(grade_predictions['Predição das notas'] >= 12, other=0)
grade_predictions['Conceito Final'] = grade_predictions['Conceito Final'].where(grade_predictions['Conceito Final'] == False, other=1)
grade_predictions

"""# **Resultados**

**Árvores de decisão:**

Precisão: 67%

recall: 100%

f1-score: 80%

acurácia: 42%



**SVM:**

Precisão: 100%

recall: 0%

f1-score: 0%

acurácia: 36%



**Regrssão logistica:**

Precisão: 57%

recall: 100%

f1-score: 73%

acurácia: 42%


De maneira geral, as árvores de decisão tiveram um resultado melhor. A regressão
logistica teve um resultado semelhante. A SVM eu estranhei os resultados, talvez
eu possa ter confundido o valor das classes para a análise.
"""

