# -*- coding: utf-8 -*-
"""StudentPerfomanceAnalysis.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1htbOg5VqSH6fXXiGeMI2cvFlAh6fGCsq

# **Explicação de como foi feita a atividade**

1 - Foi utilizado o dataset dos estudantes de português.

2 - Foi verificado se existiam dados duplicados: O resultado foi que não existiam, desta forma, nenhum tratamento foi realizado.

3 - Foi verificado se existiam dados nulos; O resultado foi que não existiam, desta forma, nenhum tratamento foi realizado.

4 - Algumas variáveis categóricas foram transformadas em numéricas para que fosse possível utiliza-las no treinamento do modelo.

5 - Algums variáveis foram removidas pois no MEU entendimento não pareciam relevantes para uma análise, mas isso depende do ponto de vista, é claro.

6 - Foi gerado um primeiro heatmap com o objetivo de entender quais variáveis estavam mais correlacionadas dentro do dataframe já filtrado. O segundo heatmap foi gerado após a seleção de quais variáveis seriam utilizadas no treinamento.

7 - Utilizei uma regressão linear para realizar a atividade, embora ela não retorne classes como resultado final (aprovado ou reprovado, por exemplo), ela me prediz uma nota baseada no dataset de treinamento e com essa nota eu consigo dizer se para um aluno do dataset de teste, se ele foi aprovado ou não.

8 - No final foi gerado um novo dataframe com das colunas: A primeira com as notas preditas. A segunda coluna com False para notas menores que 12 e True para notas maiores ou iguais a 12.

9 - A saída é um csv com as respostas.
"""

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression

# dados da base de matemática
port_data = pd.read_csv("students/student-por.csv", delimiter=';')
port_data

port_data.shape

# tipos das colunas
port_data.dtypes

# verificando total de dados duplicados
port_data.duplicated().sum()

# verficando colunas com valores NaN
port_data.isna().any()

# convertendo variáveis categóricas para numéricas

# [GP = 0, MS = 1]
port_data['school'].replace(['GP','MS'], [0,1], inplace=True)

# [F = 0, M = 1]
port_data['sex'].replace(['F','M'], [0,1], inplace=True)

# [U = 0, R = 1]
port_data['address'].replace(['U','R'], [0,1], inplace=True)

# [LE3 = 0, GT3 = 1]
port_data['famsize'].replace(['LE3','GT3'], [0,1], inplace=True)

# [T = 0, A = 1]
port_data['Pstatus'].replace(['T','A'], [0,1], inplace=True)

# [teacher = 0, health = 1, services = 2, at_home = 3, other = 4]
port_data['Mjob'].replace(['teacher','health','services','at_home','other'], [0,1,2,3,4], inplace=True)
port_data['Fjob'].replace(['teacher','health','services','at_home','other'], [0,1,2,3,4], inplace=True)

# [mother = 0, father = 1, other = 2]
port_data['guardian'].replace(['mother','father','other'], [0,1,2], inplace=True)

# [no = 0, yes = 1]
port_data['schoolsup'].replace(['no','yes'], [0,1], inplace=True)

# [no = 0, yes = 1]
port_data['famsup'].replace(['no','yes'], [0,1], inplace=True)

# [no = 0, yes = 1]
port_data['paid'].replace(['no','yes'], [0,1], inplace=True)

# [no = 0, yes = 1]
port_data['activities'].replace(['no','yes'], [0,1], inplace=True)

# [no = 0, yes = 1]
port_data['nursery'].replace(['no','yes'], [0,1], inplace=True)

# [no = 0, yes = 1]
port_data['higher'].replace(['no','yes'], [0,1], inplace=True)

# [no = 0, yes = 1]
port_data['internet'].replace(['no','yes'], [0,1], inplace=True)

# [no = 0, yes = 1]
port_data['romantic'].replace(['no','yes'], [0,1], inplace=True)

port_data

# tirando algumas colunas que para mim não são necessárias
df = port_data
df = df.drop(['Mjob', 'Fjob', 'reason', 'romantic'], axis=1)
df

# Gerando um heatmap para enteder quais variáveis estão mais correlacionadas
sns.heatmap(df.corr(), xticklabels=True, yticklabels=True, annot=False, vmin=-1, vmax=1, cmap='coolwarm')
plt.show()

# y -> target (variavel dependete)
# x -> variaveis independentes
y = df[["G3"]]
x = df[["Medu", "Fedu", "studytime", "higher", "internet", "schoolsup", "famsup", "freetime", "goout", "Dalc", "Walc", "G1", "G2"]]

# Gerando um novo heatmap apenas com as variáveis selecionadas para o treinamento
sns.heatmap(x.corr(), xticklabels=True, yticklabels=True, annot=False, vmin=-1, vmax=1, cmap='coolwarm')
plt.show()

# fazendo split do dataset
x_train, x_test, y_train, y_test = train_test_split(x, y)

# criando um modelo de regressão linear
reg = LinearRegression()
reg.fit(x_train, y_train)

reg.score(x_train, y_train)

# predicoes
y_pred = reg.predict(x_test)
y_pred

# passando o vetor das predições para um dataframe
grade_predictions = pd.DataFrame(y_pred, columns=['Predição das notas'])
grade_predictions

# inserindo uma nova coluna para conceito
grade_predictions.insert(1, "Conceito Final", True)

cols = grade_predictions.columns.tolist()
cols

grade_predictions['Conceito Final'] = grade_predictions['Predição das notas'].where(grade_predictions['Predição das notas'] >= 12, other=False)
grade_predictions['Conceito Final'] = grade_predictions['Conceito Final'].where(grade_predictions['Conceito Final'] == False, other=True)
grade_predictions

grade_predictions.to_csv('out.csv', index=False)